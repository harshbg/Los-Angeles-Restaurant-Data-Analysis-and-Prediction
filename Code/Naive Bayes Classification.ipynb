{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\Siddharth\\\\Documents\\\\Study Material\\\\Informs\\\\Owner and grade.csv',encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OWNER NAME</th>\n",
       "      <th>FACILITY ZIP</th>\n",
       "      <th>FACILITY ADDRESS</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUCY'S DRIVE THRU INC</td>\n",
       "      <td>90230</td>\n",
       "      <td>11204 WASHINGTON PL</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAUL V ANAND</td>\n",
       "      <td>91405</td>\n",
       "      <td>14102 SHERMAN WAY</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHARR, INC</td>\n",
       "      <td>90220</td>\n",
       "      <td>15228 S AVALON BLVD</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARISCAL, ESTELA</td>\n",
       "      <td>90255</td>\n",
       "      <td>2871 E GAGE AVE</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAWA SUPERMARKET, INC</td>\n",
       "      <td>91007</td>\n",
       "      <td>1300 S GOLDEN WEST AVE</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OWNER NAME  FACILITY ZIP        FACILITY ADDRESS GRADE\n",
       "0  LUCY'S DRIVE THRU INC         90230     11204 WASHINGTON PL     A\n",
       "1           PAUL V ANAND         91405       14102 SHERMAN WAY     A\n",
       "2             CHARR, INC         90220     15228 S AVALON BLVD     A\n",
       "3       MARISCAL, ESTELA         90255         2871 E GAGE AVE     A\n",
       "4  TAWA SUPERMARKET, INC         91007  1300 S GOLDEN WEST AVE     A"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['OWNER NAME']]\n",
    "y=df[['GRADE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (32220, 1), shape of test (10740, 1)\n"
     ]
    }
   ],
   "source": [
    "#Splitting train and test datasets \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X, y, random_state = 100)\n",
    "\n",
    "print('Shape of train {}, shape of test {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(str_arg):\n",
    "    \n",
    "    \"\"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        str_arg: example string to be preprocessed\n",
    "        \n",
    "        What the function does?\n",
    "        -----------------------\n",
    "        Preprocess the string argument - str_arg - such that :\n",
    "        1. everything apart from letters is excluded\n",
    "        2. multiple spaces are replaced by single space\n",
    "        3. str_arg is converted to lower case \n",
    "        \n",
    "        Example:\n",
    "        --------\n",
    "        Input :  Menu is absolutely perfect,loved it!\n",
    "        Output:  ['menu', 'is', 'absolutely', 'perfect', 'loved', 'it']\n",
    "        \n",
    "        Returns:\n",
    "        ---------\n",
    "        Preprocessed string \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_str=re.sub('[^a-z\\s]+',' ',str_arg,flags=re.IGNORECASE) #every char except alphabets is replaced\n",
    "    cleaned_str=re.sub('(\\s+)',' ',cleaned_str) #multiple spaces are replaced by single space\n",
    "    cleaned_str=cleaned_str.lower() #converting the cleaned string to lower case\n",
    "    \n",
    "    return cleaned_str # returning the preprocessed string "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self,unique_classes):\n",
    "        \n",
    "        self.classes=unique_classes # Constructor is sinply passed with unique number of classes of the training set\n",
    "        \n",
    "\n",
    "    def addToBow(self,example,dict_index):\n",
    "        \n",
    "        '''\n",
    "            Parameters:\n",
    "            1. example \n",
    "            2. dict_index - implies to which BoW category this example belongs to\n",
    "            What the function does?\n",
    "            -----------------------\n",
    "            It simply splits the example on the basis of space as a tokenizer and adds every tokenized word to\n",
    "            its corresponding dictionary/BoW\n",
    "            Returns:\n",
    "            ---------\n",
    "            Nothing\n",
    "        \n",
    "       '''\n",
    "        \n",
    "        if isinstance(example,np.ndarray): example=example[0]\n",
    "     \n",
    "        for token_word in example.split(): #for every word in preprocessed example\n",
    "          \n",
    "            self.bow_dicts[dict_index][token_word]+=1 #increment in its count\n",
    "            \n",
    "    def train(self,dataset,labels):\n",
    "        \n",
    "        '''\n",
    "            Parameters:\n",
    "            1. dataset - shape = (m X d)\n",
    "            2. labels - shape = (m,)\n",
    "            What the function does?\n",
    "            -----------------------\n",
    "            This is the training function which will train the Naive Bayes Model i.e compute a BoW for each\n",
    "            category/class. \n",
    "            Returns:\n",
    "            ---------\n",
    "            Nothing\n",
    "        \n",
    "        '''\n",
    "    \n",
    "        self.examples=dataset\n",
    "        self.labels=labels\n",
    "        self.bow_dicts=np.array([defaultdict(lambda:0) for index in range(self.classes.shape[0])])\n",
    "        \n",
    "        #only convert to numpy arrays if initially not passed as numpy arrays - else its a useless recomputation\n",
    "        \n",
    "        if not isinstance(self.examples,np.ndarray): self.examples=np.array(self.examples)\n",
    "        if not isinstance(self.labels,np.ndarray): self.labels=np.array(self.labels)\n",
    "            \n",
    "        #constructing BoW for each category\n",
    "        for cat_index,cat in enumerate(self.classes):\n",
    "          \n",
    "            all_cat_examples=self.examples[self.labels==cat] #filter all examples of category == cat\n",
    "            \n",
    "            #get examples preprocessed\n",
    "            \n",
    "            cleaned_examples=[preprocess_string(cat_example) for cat_example in all_cat_examples]\n",
    "            \n",
    "            cleaned_examples=pd.DataFrame(data=cleaned_examples)\n",
    "            \n",
    "            #now costruct BoW of this particular category\n",
    "            np.apply_along_axis(self.addToBow,1,cleaned_examples,cat_index)\n",
    "            \n",
    "                \n",
    "        ###################################################################################################\n",
    "        \n",
    "        '''\n",
    "            Although we are done with the training of Naive Bayes Model BUT!!!!!!\n",
    "            ------------------------------------------------------------------------------------\n",
    "            Remember The Test Time Forumla ? : {for each word w [ count(w|c)+1 ] / [ count(c) + |V| + 1 ] } * p(c)\n",
    "            ------------------------------------------------------------------------------------\n",
    "            \n",
    "            We are done with constructing of BoW for each category. But we need to precompute a few \n",
    "            other calculations at training time too:\n",
    "            1. prior probability of each class - p(c)\n",
    "            2. vocabulary |V| \n",
    "            3. denominator value of each class - [ count(c) + |V| + 1 ] \n",
    "            \n",
    "            Reason for doing this precomputing calculations stuff ???\n",
    "            ---------------------\n",
    "            We can do all these 3 calculations at test time too BUT doing so means to re-compute these \n",
    "            again and again every time the test function will be called - this would significantly\n",
    "            increase the computation time especially when we have a lot of test examples to classify!!!).  \n",
    "            And moreover, it doensot make sense to repeatedly compute the same thing - \n",
    "            why do extra computations ???\n",
    "            So we will precompute all of them & use them during test time to speed up predictions.\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        ###################################################################################################\n",
    "      \n",
    "        prob_classes=np.empty(self.classes.shape[0])\n",
    "        all_words=[]\n",
    "        cat_word_counts=np.empty(self.classes.shape[0])\n",
    "        for cat_index,cat in enumerate(self.classes):\n",
    "           \n",
    "            #Calculating prior probability p(c) for each class\n",
    "            prob_classes[cat_index]=np.sum(self.labels==cat)/float(self.labels.shape[0]) \n",
    "            \n",
    "            #Calculating total counts of all the words of each class \n",
    "            count=list(self.bow_dicts[cat_index].values())\n",
    "            cat_word_counts[cat_index]=np.sum(np.array(list(self.bow_dicts[cat_index].values())))+1 # |v| is remaining to be added\n",
    "            \n",
    "            #get all words of this category                                \n",
    "            all_words+=self.bow_dicts[cat_index].keys()\n",
    "                                                     \n",
    "        \n",
    "        #combine all words of every category & make them unique to get vocabulary -V- of entire training set\n",
    "        \n",
    "        self.vocab=np.unique(np.array(all_words))\n",
    "        self.vocab_length=self.vocab.shape[0]\n",
    "                                  \n",
    "        #computing denominator value                                      \n",
    "        denoms=np.array([cat_word_counts[cat_index]+self.vocab_length+1 for cat_index,cat in enumerate(self.classes)])                                                                          \n",
    "      \n",
    "        '''\n",
    "            Now that we have everything precomputed as well, its better to organize everything in a tuple \n",
    "            rather than to have a separate list for every thing.\n",
    "            \n",
    "            Every element of self.cats_info has a tuple of values\n",
    "            Each tuple has a dict at index 0, prior probability at index 1, denominator value at index 2\n",
    "        '''\n",
    "        \n",
    "        self.cats_info=[(self.bow_dicts[cat_index],prob_classes[cat_index],denoms[cat_index]) for cat_index,cat in enumerate(self.classes)]                               \n",
    "        self.cats_info=np.array(self.cats_info)                                 \n",
    "                                              \n",
    "                                              \n",
    "    def getExampleProb(self,test_example):                                \n",
    "        \n",
    "        '''\n",
    "            Parameters:\n",
    "            -----------\n",
    "            1. a single test example \n",
    "            What the function does?\n",
    "            -----------------------\n",
    "            Function that estimates posterior probability of the given test example\n",
    "            Returns:\n",
    "            ---------\n",
    "            probability of test example in ALL CLASSES\n",
    "        '''                                      \n",
    "                                              \n",
    "        likelihood_prob=np.zeros(self.classes.shape[0]) #to store probability w.r.t each class\n",
    "        \n",
    "        #finding probability w.r.t each class of the given test example\n",
    "        for cat_index,cat in enumerate(self.classes): \n",
    "                             \n",
    "            for test_token in test_example.split(): #split the test example and get p of each test word\n",
    "                \n",
    "                ####################################################################################\n",
    "                                              \n",
    "                #This loop computes : for each word w [ count(w|c)+1 ] / [ count(c) + |V| + 1 ]                               \n",
    "                                              \n",
    "                ####################################################################################                              \n",
    "                \n",
    "                #get total count of this test token from it's respective training dict to get numerator value                           \n",
    "                test_token_counts=self.cats_info[cat_index][0].get(test_token,0)+1\n",
    "                \n",
    "                #now get likelihood of this test_token word                              \n",
    "                test_token_prob=test_token_counts/float(self.cats_info[cat_index][2])                              \n",
    "                \n",
    "                #remember why taking log? To prevent underflow!\n",
    "                likelihood_prob[cat_index]+=np.log(test_token_prob)\n",
    "                                              \n",
    "        # we have likelihood estimate of the given example against every class but we need posterior probility\n",
    "        post_prob=np.empty(self.classes.shape[0])\n",
    "        for cat_index,cat in enumerate(self.classes):\n",
    "            post_prob[cat_index]=likelihood_prob[cat_index]+np.log(self.cats_info[cat_index][1])                                  \n",
    "      \n",
    "        return post_prob\n",
    "    \n",
    "   \n",
    "    def test(self,test_set):\n",
    "      \n",
    "        '''\n",
    "            Parameters:\n",
    "            -----------\n",
    "            1. A complete test set of shape (m,)\n",
    "            \n",
    "            What the function does?\n",
    "            -----------------------\n",
    "            Determines probability of each test example against all classes and predicts the label\n",
    "            against which the class probability is maximum\n",
    "            Returns:\n",
    "            ---------\n",
    "            Predictions of test examples - A single prediction against every test example\n",
    "        '''       \n",
    "       \n",
    "        predictions=[] #to store prediction of each test example\n",
    "        for example in test_set: \n",
    "                                              \n",
    "            #preprocess the test example the same way we did for training set exampels                                  \n",
    "            cleaned_example=preprocess_string(example) \n",
    "             \n",
    "            #simply get the posterior probability of every example                                  \n",
    "            post_prob=self.getExampleProb(cleaned_example) #get prob of this example for both classes\n",
    "            \n",
    "            #simply pick the max value and map against self.classes!\n",
    "            predictions.append(self.classes[np.argmax(post_prob)])\n",
    "                \n",
    "        return np.array(predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Training In Progress --------------------\n",
      "----------------- Training Completed ---------------------\n"
     ]
    }
   ],
   "source": [
    "nb=NaiveBayes(np.unique(train_labels)) #instantiate a NB class object\n",
    "print (\"---------------- Training In Progress --------------------\")\n",
    " \n",
    "nb.train(train_data,train_labels) #start tarining by calling the train function\n",
    "print ('----------------- Training Completed ---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Examples:  10740\n",
      "Test Set Accuracy:  GRADE    82.886406\n",
      "dtype: float64 %\n"
     ]
    }
   ],
   "source": [
    "pclasses=nb.test(test_data) #get predcitions for test set\n",
    "\n",
    "#check how many predcitions actually match original test labels\n",
    "test_acc=np.sum(pclasses==test_labels)/float(test_labels.shape[0]) \n",
    "\n",
    "print (\"Test Set Examples: \",test_labels.shape[0]) # Outputs : Test Set Examples:  1502\n",
    "print (\"Test Set Accuracy: \",test_acc*100,\"%\") # Outputs : Test Set Accuracy:  93.8748335553 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multinomial Naive Bayes (Only Owner Name Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRADE']=df['GRADE'].map({'A':1,'B':2,'C':3,'D':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['OWNER NAME']\n",
    "Y=df['GRADE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.83      0.94      0.88     11796\n",
      "          2       0.04      0.01      0.02      2109\n",
      "          3       0.00      0.00      0.00       252\n",
      "          4       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.69      0.79      0.74     14177\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddharth\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running it on a Smaller datasets (Under Sampling)\n",
    "As the data is very imbalanced we decided to run the models on undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['GRADE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRADE'].unique()\n",
    "df['GRADE']=df['GRADE'].map({'A':1,'B':2,'C':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OWNER NAME</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUCY'S DRIVE THRU INC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAUL V ANAND</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHARR, INC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARISCAL, ESTELA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAWA SUPERMARKET, INC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OWNER NAME  GRADE\n",
       "0  LUCY'S DRIVE THRU INC      1\n",
       "1           PAUL V ANAND      1\n",
       "2             CHARR, INC      1\n",
       "3       MARISCAL, ESTELA      1\n",
       "4  TAWA SUPERMARKET, INC      1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['OWNER NAME']\n",
    "Y=df['GRADE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade1_index=Y[Y.values==1].index\n",
    "grade2_index=Y[Y.values==2].index\n",
    "grade3_index=Y[Y.values==3].index\n",
    "\n",
    "highest=grade1_index\n",
    "higher=grade2_index\n",
    "lower=grade3_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember higher is a list of indexes, either of 0 or 1's in the response variable in training set\n",
    "higher=np.random.choice(higher, size=2*len(lower))\n",
    "highest=np.random.choice(highest, size=2*len(lower))\n",
    "\n",
    "lower=np.asarray(lower)\n",
    "\n",
    "new_indexes=np.concatenate((lower,higher,highest))\n",
    "\n",
    "X=X.loc[new_indexes,]\n",
    "Y=Y.loc[new_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3965x4570 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11561 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.44      0.57      0.50       497\n",
      "          2       0.45      0.51      0.48       527\n",
      "          3       0.17      0.04      0.07       285\n",
      "\n",
      "avg / total       0.39      0.43      0.40      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=df['OWNER NAME']\n",
    "##cv=CountVectorizer()\n",
    "##X1=cv.fit_transform(X1)\n",
    "X1\n",
    "Y1=df['GRADE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X1)\n",
    "print(classification_report(Y1, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adding Zip and Address to the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('C:\\\\Users\\\\Siddharth\\\\Documents\\\\Study Material\\\\Informs\\\\Zip, Address.csv',encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FACILITY ADDRESS</th>\n",
       "      <th>FACILITY ZIP</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11204 WASHINGTON PL</td>\n",
       "      <td>90230</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14102 SHERMAN WAY</td>\n",
       "      <td>91405</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15228 S AVALON BLVD</td>\n",
       "      <td>90220</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2871 E GAGE AVE</td>\n",
       "      <td>90255</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1300 S GOLDEN WEST AVE</td>\n",
       "      <td>91007</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FACILITY ADDRESS  FACILITY ZIP GRADE\n",
       "0     11204 WASHINGTON PL         90230     A\n",
       "1       14102 SHERMAN WAY         91405     A\n",
       "2     15228 S AVALON BLVD         90220     A\n",
       "3         2871 E GAGE AVE         90255     A\n",
       "4  1300 S GOLDEN WEST AVE         91007     A"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['GRADE'].unique()\n",
    "df1['GRADE']=df1['GRADE'].map({'A':1,'B':2,'C':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FACILITY ADDRESS</th>\n",
       "      <th>FACILITY ZIP</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11204 WASHINGTON PL</td>\n",
       "      <td>90230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14102 SHERMAN WAY</td>\n",
       "      <td>91405</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15228 S AVALON BLVD</td>\n",
       "      <td>90220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2871 E GAGE AVE</td>\n",
       "      <td>90255</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1300 S GOLDEN WEST AVE</td>\n",
       "      <td>91007</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FACILITY ADDRESS  FACILITY ZIP  GRADE\n",
       "0     11204 WASHINGTON PL         90230    1.0\n",
       "1       14102 SHERMAN WAY         91405    1.0\n",
       "2     15228 S AVALON BLVD         90220    1.0\n",
       "3         2871 E GAGE AVE         90255    1.0\n",
       "4  1300 S GOLDEN WEST AVE         91007    1.0"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FACILITY ADDRESS    0\n",
       "FACILITY ZIP        0\n",
       "GRADE               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1.dropna()\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['FACILITY ZIP'] = df1['FACILITY ZIP'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FACILITY ADDRESS     object\n",
       "FACILITY ZIP         object\n",
       "GRADE               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X=df1['FACILITY ADDRESS']\n",
    "Y=df1['GRADE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.95      1.00      0.97     64039\n",
      "        2.0       0.18      0.01      0.03      3270\n",
      "        3.0       0.00      0.00      0.00       306\n",
      "\n",
      "avg / total       0.91      0.94      0.92     67615\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddharth\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade1_index=Y[Y.values==1].index\n",
    "grade2_index=Y[Y.values==2].index\n",
    "grade3_index=Y[Y.values==3].index\n",
    "\n",
    "highest=grade1_index\n",
    "higher=grade2_index\n",
    "lower=grade3_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember higher is a list of indexes, either of 0 or 1's in the response variable in training set\n",
    "higher=np.random.choice(higher, size=2*len(lower))\n",
    "highest=np.random.choice(highest, size=2*len(lower))\n",
    "\n",
    "lower=np.asarray(lower)\n",
    "\n",
    "new_indexes=np.concatenate((lower,higher,highest))\n",
    "\n",
    "X=X.loc[new_indexes,]\n",
    "Y=Y.loc[new_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4555x3601 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15495 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.50      0.55      0.53       603\n",
      "        2.0       0.47      0.60      0.53       607\n",
      "        3.0       0.43      0.11      0.17       294\n",
      "\n",
      "avg / total       0.48      0.49      0.46      1504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Trying different Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('C:\\\\Users\\\\Siddharth\\\\Documents\\\\Study Material\\\\Informs\\\\Zip, Address.csv',encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OWNER NAME</th>\n",
       "      <th>FACILITY ADDRESS</th>\n",
       "      <th>FACILITY ZIP</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUCY'S DRIVE THRU INC</td>\n",
       "      <td>11204 WASHINGTON PL</td>\n",
       "      <td>90230</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAUL V ANAND</td>\n",
       "      <td>14102 SHERMAN WAY</td>\n",
       "      <td>91405</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHARR, INC</td>\n",
       "      <td>15228 S AVALON BLVD</td>\n",
       "      <td>90220</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARISCAL, ESTELA</td>\n",
       "      <td>2871 E GAGE AVE</td>\n",
       "      <td>90255</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAWA SUPERMARKET, INC</td>\n",
       "      <td>1300 S GOLDEN WEST AVE</td>\n",
       "      <td>91007</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OWNER NAME        FACILITY ADDRESS  FACILITY ZIP GRADE\n",
       "0  LUCY'S DRIVE THRU INC     11204 WASHINGTON PL         90230     A\n",
       "1           PAUL V ANAND       14102 SHERMAN WAY         91405     A\n",
       "2             CHARR, INC     15228 S AVALON BLVD         90220     A\n",
       "3       MARISCAL, ESTELA         2871 E GAGE AVE         90255     A\n",
       "4  TAWA SUPERMARKET, INC  1300 S GOLDEN WEST AVE         91007     A"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OWNER NAME          0\n",
       "FACILITY ADDRESS    0\n",
       "FACILITY ZIP        0\n",
       "GRADE               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1.dropna()\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X=df1[['FACILITY ADDRESS','FACILITY ZIP']]\n",
    "Y=df1[['GRADE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade1_index=Y[Y.values=='A'].index\n",
    "grade2_index=Y[Y.values=='B'].index\n",
    "grade3_index=Y[Y.values=='C'].index\n",
    "\n",
    "highest=grade1_index\n",
    "higher=grade2_index\n",
    "lower=grade3_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember higher is a list of indexes, either of 0 or 1's in the response variable in training set\n",
    "higher=np.random.choice(higher, size=2*len(lower))\n",
    "highest=np.random.choice(highest, size=2*len(lower))\n",
    "\n",
    "lower=np.asarray(lower)\n",
    "\n",
    "new_indexes=np.concatenate((lower,higher,highest))\n",
    "\n",
    "X=X.loc[new_indexes,]\n",
    "Y=Y.loc[new_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FACILITY ADDRESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10905 MAGNOLIA BLVD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>15321 ROSCOE BLVD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>3803 W BURBANK BLVD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>1695 S AZUSA AVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>3225 E PACIFIC COAST HWY #A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 FACILITY ADDRESS\n",
       "20            10905 MAGNOLIA BLVD\n",
       "384             15321 ROSCOE BLVD\n",
       "607           3803 W BURBANK BLVD\n",
       "1258             1695 S AZUSA AVE\n",
       "1565  3225 E PACIFIC COAST HWY #A"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['FACILITY ZIP'] = df1['FACILITY ZIP'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X=df1['FACILITY ADDRESS']\n",
    "Y=df1['GRADE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<204892x15382 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 692897 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X1=df1['FACILITY ZIP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<204892x396 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 204892 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X1=cv.fit_transform(X1)\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "Combined=hstack((X, X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Combined, Y, test_size=0.33, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.95      1.00      0.97     64039\n",
      "          B       0.25      0.03      0.06      3270\n",
      "          C       0.00      0.00      0.00       306\n",
      "\n",
      "avg / total       0.91      0.94      0.92     67615\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddharth\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combining All three Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('C:\\\\Users\\\\Siddharth\\\\Documents\\\\Study Material\\\\Informs\\\\Zip, Address.csv',encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OWNER NAME</th>\n",
       "      <th>FACILITY NAME</th>\n",
       "      <th>FACILITY ADDRESS</th>\n",
       "      <th>FACILITY ZIP</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUCY'S DRIVE THRU INC</td>\n",
       "      <td>5 DE MAYO</td>\n",
       "      <td>11204 WASHINGTON PL</td>\n",
       "      <td>90650</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAUL V ANAND</td>\n",
       "      <td>7-ELEVEN STORE 18341D</td>\n",
       "      <td>14102 SHERMAN WAY</td>\n",
       "      <td>91744</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHARR, INC</td>\n",
       "      <td>7-ELEVEN STORE 37021A</td>\n",
       "      <td>15228 S AVALON BLVD</td>\n",
       "      <td>90028</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARISCAL, ESTELA</td>\n",
       "      <td>98 CENT DISCOUT STORE &amp; MKT</td>\n",
       "      <td>2871 E GAGE AVE</td>\n",
       "      <td>90046</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAWA SUPERMARKET, INC</td>\n",
       "      <td>99 RANCH MARKET #7</td>\n",
       "      <td>1300 S GOLDEN WEST AVE</td>\n",
       "      <td>91605</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OWNER NAME                FACILITY NAME        FACILITY ADDRESS  \\\n",
       "0  LUCY'S DRIVE THRU INC                    5 DE MAYO     11204 WASHINGTON PL   \n",
       "1           PAUL V ANAND        7-ELEVEN STORE 18341D       14102 SHERMAN WAY   \n",
       "2             CHARR, INC        7-ELEVEN STORE 37021A     15228 S AVALON BLVD   \n",
       "3       MARISCAL, ESTELA  98 CENT DISCOUT STORE & MKT         2871 E GAGE AVE   \n",
       "4  TAWA SUPERMARKET, INC           99 RANCH MARKET #7  1300 S GOLDEN WEST AVE   \n",
       "\n",
       "  FACILITY ZIP GRADE  \n",
       "0        90650     A  \n",
       "1        91744     A  \n",
       "2        90028     A  \n",
       "3        90046     A  \n",
       "4        91605     A  "
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OWNER NAME          0\n",
       "FACILITY NAME       0\n",
       "FACILITY ADDRESS    0\n",
       "FACILITY ZIP        0\n",
       "GRADE               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1.dropna()\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X=df1[['FACILITY ADDRESS','FACILITY ZIP']]\n",
    "Y=df1[['GRADE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['FACILITY ZIP'] = df1['FACILITY ZIP'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X=df1['FACILITY ADDRESS']\n",
    "Y=df1['GRADE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<204892x15382 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 692897 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X1=df1['FACILITY ZIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<204892x2515 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 220284 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X1=cv.fit_transform(X1)\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X2=df1['OWNER NAME']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<204892x24677 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 611589 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X2=cv.fit_transform(X2)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "Comb=hstack((X2, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined=hstack((Comb, X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Combined, Y, test_size=0.33, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.95      0.98      0.97     64039\n",
      "          B       0.20      0.10      0.13      3270\n",
      "          C       0.00      0.00      0.00       306\n",
      "\n",
      "avg / total       0.91      0.93      0.92     67615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Running it on Smaller Dataset and all the 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('C:\\\\Users\\\\Siddharth\\\\Documents\\\\Study Material\\\\Informs\\\\Zip, Address.csv',encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', nan], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['GRADE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OWNER NAME          0\n",
       "FACILITY NAME       0\n",
       "FACILITY ADDRESS    0\n",
       "FACILITY ZIP        0\n",
       "GRADE               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1.dropna()\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['GRADE']=df1['GRADE'].map({'A':1,'B':2,'C':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df1['OWNER NAME']\n",
    "X1=df1['FACILITY ADDRESS']\n",
    "X2=df1['FACILITY ZIP']\n",
    "X3=df1['FACILITY NAME']\n",
    "Y=df1['GRADE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OWNER NAME</th>\n",
       "      <th>FACILITY NAME</th>\n",
       "      <th>FACILITY ADDRESS</th>\n",
       "      <th>FACILITY ZIP</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUCY'S DRIVE THRU INC</td>\n",
       "      <td>5 DE MAYO</td>\n",
       "      <td>11204 WASHINGTON PL</td>\n",
       "      <td>90650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAUL V ANAND</td>\n",
       "      <td>7-ELEVEN STORE 18341D</td>\n",
       "      <td>14102 SHERMAN WAY</td>\n",
       "      <td>91744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHARR, INC</td>\n",
       "      <td>7-ELEVEN STORE 37021A</td>\n",
       "      <td>15228 S AVALON BLVD</td>\n",
       "      <td>90028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARISCAL, ESTELA</td>\n",
       "      <td>98 CENT DISCOUT STORE &amp; MKT</td>\n",
       "      <td>2871 E GAGE AVE</td>\n",
       "      <td>90046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAWA SUPERMARKET, INC</td>\n",
       "      <td>99 RANCH MARKET #7</td>\n",
       "      <td>1300 S GOLDEN WEST AVE</td>\n",
       "      <td>91605</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OWNER NAME                FACILITY NAME        FACILITY ADDRESS  \\\n",
       "0  LUCY'S DRIVE THRU INC                    5 DE MAYO     11204 WASHINGTON PL   \n",
       "1           PAUL V ANAND        7-ELEVEN STORE 18341D       14102 SHERMAN WAY   \n",
       "2             CHARR, INC        7-ELEVEN STORE 37021A     15228 S AVALON BLVD   \n",
       "3       MARISCAL, ESTELA  98 CENT DISCOUT STORE & MKT         2871 E GAGE AVE   \n",
       "4  TAWA SUPERMARKET, INC           99 RANCH MARKET #7  1300 S GOLDEN WEST AVE   \n",
       "\n",
       "  FACILITY ZIP  GRADE  \n",
       "0        90650      1  \n",
       "1        91744      1  \n",
       "2        90028      1  \n",
       "3        90046      1  \n",
       "4        91605      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['GRADE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade1_index=Y[Y.values==1].index\n",
    "grade2_index=Y[Y.values==2].index\n",
    "grade3_index=Y[Y.values==3].index\n",
    "\n",
    "highest=grade1_index\n",
    "higher=grade2_index\n",
    "lower=grade3_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     5,     21,     22,     37,     52,     59,     69,     96,\n",
       "                97,    132,\n",
       "            ...\n",
       "            204513, 204522, 204534, 204568, 204632, 204679, 204806, 204845,\n",
       "            204925, 204927],\n",
       "           dtype='int64', length=9729)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember higher is a list of indexes, either of 0 or 1's in the response variable in training set\n",
    "higher=np.random.choice(higher, size=5*len(lower))\n",
    "highest=np.random.choice(highest, size=8*len(lower))\n",
    "\n",
    "lower=np.asarray(lower)\n",
    "\n",
    "new_indexes=np.concatenate((lower,higher,highest))\n",
    "\n",
    "X=X.loc[new_indexes,]\n",
    "X1=X1.loc[new_indexes,]\n",
    "X2=X2.loc[new_indexes,]\n",
    "X3=X3.loc[new_indexes,]\n",
    "Y=Y.loc[new_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame123=pd.concat([X,X1,X2,X3,Y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OWNER NAME</th>\n",
       "      <th>FACILITY ADDRESS</th>\n",
       "      <th>FACILITY ZIP</th>\n",
       "      <th>FACILITY NAME</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VOSKANIAN, EDIK</td>\n",
       "      <td>10905 MAGNOLIA BLVD</td>\n",
       "      <td>90046</td>\n",
       "      <td>AMSTERDAM CAFE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>LEE, LEE CHAN</td>\n",
       "      <td>15321 ROSCOE BLVD</td>\n",
       "      <td>90712</td>\n",
       "      <td>USA DONUTS &amp; CROISSANTS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>BLANCHETEAU, OLGA PATRICIA</td>\n",
       "      <td>3803 W BURBANK BLVD</td>\n",
       "      <td>90401</td>\n",
       "      <td>MI LATIN KITCHEN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>DEERBROOK ENTERPRISE CORP</td>\n",
       "      <td>1695 S AZUSA AVE</td>\n",
       "      <td>90066</td>\n",
       "      <td>SHANE HAILANDER PALACE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>CHANTIDA NHEUK</td>\n",
       "      <td>3225 E PACIFIC COAST HWY #A</td>\n",
       "      <td>91601</td>\n",
       "      <td>MANNA DONUTS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      OWNER NAME             FACILITY ADDRESS FACILITY ZIP  \\\n",
       "20               VOSKANIAN, EDIK          10905 MAGNOLIA BLVD        90046   \n",
       "384                LEE, LEE CHAN            15321 ROSCOE BLVD        90712   \n",
       "607   BLANCHETEAU, OLGA PATRICIA          3803 W BURBANK BLVD        90401   \n",
       "1258   DEERBROOK ENTERPRISE CORP             1695 S AZUSA AVE        90066   \n",
       "1565              CHANTIDA NHEUK  3225 E PACIFIC COAST HWY #A        91601   \n",
       "\n",
       "                FACILITY NAME  GRADE  \n",
       "20             AMSTERDAM CAFE      3  \n",
       "384   USA DONUTS & CROISSANTS      3  \n",
       "607          MI LATIN KITCHEN      3  \n",
       "1258   SHANE HAILANDER PALACE      3  \n",
       "1565             MANNA DONUTS      3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame123.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame123['GRADE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame123['FACILITY ZIP'] = DataFrame123['FACILITY ZIP'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X=DataFrame123['FACILITY ADDRESS']\n",
    "Y=DataFrame123['GRADE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148633    6800 RESEDA BLVD STE B\n",
       "84015          4356 BEVERLY BLVD\n",
       "49132           3161 N GAREY AVE\n",
       "199248       2600 W VICTORY BLVD\n",
       "39147      247 AVENIDA DEL NORTE\n",
       "Name: FACILITY ADDRESS, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12754x6730 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 43178 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X1=DataFrame123['FACILITY ZIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12754x946 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13706 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X1=cv.fit_transform(X1)\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X2=DataFrame123['OWNER NAME']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12754x8553 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 37738 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X2=cv.fit_transform(X2)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df1[['FACILITY ZIP','FACILITY ADDRESS']]\n",
    "X3=DataFrame123['FACILITY NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12754x7097 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 34500 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X3=cv.fit_transform(X3)\n",
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "Comb=hstack((X2, X3))\n",
    "comb=hstack((Comb, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined=hstack((comb, X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12754x23504 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 129247 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3, Y, test_size=0.27, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.76      0.73      1996\n",
      "          2       0.52      0.53      0.52      1220\n",
      "          3       0.25      0.03      0.05       228\n",
      "\n",
      "avg / total       0.60      0.63      0.61      3444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "clf = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "a=classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Classifier\n",
    "clf = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "clf.fit(X,y)\n",
    "clf.score(X,y)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "a=classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_prob=pd.DataFrame(clf.predict_proba(X_train))\n",
    "#X_test_prob=pd.DataFrame(clf.predict_proba(X_test))\n",
    "#X1_train_prob=pd.DataFrame(clf.predict_proba(X_train))\n",
    "#X1_test_prob=pd.DataFrame(clf.predict_proba(X_test))\n",
    "#X2_train_prob=pd.DataFrame(clf.predict_proba(X_train))\n",
    "#X2_test_prob=pd.DataFrame(clf.predict_proba(X_test))\n",
    "X3_train_prob=pd.DataFrame(clf.predict_proba(X_train))\n",
    "X3_test_prob=pd.DataFrame(clf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3444, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3444,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3444, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_test_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9310, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9310, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test=pd.concat([X_train_prob,X1_train_prob,X2_train_prob,X3_train_prob],axis=1)\n",
    "b_test=pd.concat([X_test_prob,X1_test_prob,X2_test_prob,X3_test_prob],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train=pd.concat([a_test,y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test=pd.concat([X_train_prob,X1_train_prob,X2_train_prob,X3_train_prob,y_train],axis=1)\n",
    "b_test=pd.concat([X_test_prob,X1_test_prob,X2_test_prob,X3_test_prob,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2']}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 944,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "lreg_clf = LogisticRegression()\n",
    "\n",
    "param_grid = {'penalty':['l1', 'l2']}\n",
    "\n",
    "grid_search = GridSearchCV(lreg_clf , param_grid, cv = 5 , return_train_score=True)\n",
    "grid_search.fit(X_train_prob, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8774436090225564"
      ]
     },
     "execution_count": 945,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, f1_score\n",
    "lreg_clf = LogisticRegression(penalty = 'l2')\n",
    "lreg_clf.fit(X_train_prob, y_train)\n",
    "results = pd.DataFrame(index=None, columns=['model'])\n",
    "y_lreg_clf = lreg_clf.predict(X_test_prob)\n",
    "train_Rsquare = lreg_clf.score(X_train_prob, y_train)\n",
    "test_Rsquare = lreg_clf.score(X_test_prob, y_test)\n",
    "train_MSE = mean_squared_error(y_train, lreg_clf.predict(X_train_prob))\n",
    "test_MSE = mean_squared_error(y_test, lreg_clf.predict(X_test_prob))\n",
    "f1_score_train=f1_score(y_train, lreg_clf.predict(X_train_prob))\n",
    "f1_score_test=f1_score(y_test, lreg_clf.predict(X_test_prob))\n",
    "results = results.append(pd.Series({'model':'KNN Classifier','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE,\n",
    "                                    'f1_score_train':f1_score_train,'f1_score_test':f1_score_test}),ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8730397422126746"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg_clf.score(X_train_prob, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6454703832752613"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg_clf.score(X_test_prob, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1920515574650913"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, lreg_clf.predict(X_train_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45557491289198604"
      ]
     },
     "execution_count": 955,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, lreg_clf.predict(X_test_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [5, 10, 20, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "param_grid = {'max_depth': [5, 10, 20, 50, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(dt_clf, param_grid, cv = 5, return_train_score=True)\n",
    "grid_search.fit(X_train_prob, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5}"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8785177228786252"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_MSE</th>\n",
       "      <th>test_Rsquare</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>train_Rsquare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.623403</td>\n",
       "      <td>0.60482</td>\n",
       "      <td>0.10956</td>\n",
       "      <td>0.921375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  test_MSE  test_Rsquare  train_MSE  train_Rsquare\n",
       "0  Decision Tree Classifier  0.623403       0.60482    0.10956       0.921375"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(index=None, columns=['model'])\n",
    "dt_clf = DecisionTreeClassifier(max_depth = 10)\n",
    "dt_clf.fit(X_train_prob,y_train)\n",
    "y_dt_clf = dt_clf.predict(X_test_prob)\n",
    "train_Rsquare = dt_clf.score(X_train_prob, y_train)\n",
    "test_Rsquare = dt_clf.score(X_test_prob, y_test)\n",
    "train_MSE = mean_squared_error(y_train, dt_clf.predict(X_train_prob))\n",
    "test_MSE = mean_squared_error(y_test, dt_clf.predict(X_test_prob))\n",
    "results = results.append(pd.Series({'model':'Decision Tree Classifier','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'max_depth': [3, 5], 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002558F5787F0>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002558F578DA0>, 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 965,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "#Tuning ridge on new dataset\n",
    "param_grid = {\"max_depth\": [3, 5],\n",
    "              \"min_samples_split\": sp_randint(2, 30),\n",
    "              \"min_samples_leaf\": sp_randint(1, 20),\n",
    "              \"bootstrap\": [True, False]}\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(n_estimators=1000), param_distributions=param_grid,\n",
    "                                   n_iter=20, random_state=0,n_jobs=-1, return_train_score=True)\n",
    "random_search.fit(X_train_prob, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5}"
      ]
     },
     "execution_count": 966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882062298603652"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_MSE</th>\n",
       "      <th>test_Rsquare</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>train_Rsquare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.623403</td>\n",
       "      <td>0.604820</td>\n",
       "      <td>0.10956</td>\n",
       "      <td>0.921375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.611789</td>\n",
       "      <td>0.608595</td>\n",
       "      <td>0.16391</td>\n",
       "      <td>0.887648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  test_MSE  test_Rsquare  train_MSE  train_Rsquare\n",
       "0  Decision Tree Classifier  0.623403      0.604820    0.10956       0.921375\n",
       "1  Random Forest Classifier  0.611789      0.608595    0.16391       0.887648"
      ]
     },
     "execution_count": 969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(bootstrap=True,max_depth=5,min_samples_leaf=1,min_samples_split=5)\n",
    "rf_clf.fit(X_train_prob,y_train)\n",
    "y_rf_clf = rf_clf.predict(X_test_prob)\n",
    "train_Rsquare = rf_clf.score(X_train_prob, y_train)\n",
    "test_Rsquare = rf_clf.score(X_test_prob, y_test)\n",
    "train_MSE = mean_squared_error(y_train, rf_clf.predict(X_train_prob))\n",
    "test_MSE = mean_squared_error(y_test, rf_clf.predict(X_test_prob))\n",
    "results = results.append(pd.Series({'model':'Random Forest Classifier','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9553168635875403\n",
      "0.6146922183507549\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.5, random_state=0)\n",
    "gb.fit(X_train_prob, y_train)\n",
    "print(gb.score(X_train_prob, y_train))\n",
    "print(gb.score(X_test_prob, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
